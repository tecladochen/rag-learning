

| 方式          | 适用场景                  | 优势                          | 劣势                          |
|---------------|---------------------------|-------------------------------|-------------------------------|
| HTTP API      | 快速集成云服务            | 简单直接，无需本地资源        | 依赖网络，有调用延迟          |
| LangChain     | 复杂AI应用开发            | 模块化设计，支持链式调用      | 学习曲线较陡峭                |
| Transformers  | 本地部署/模型研究         | 完全控制模型，可离线使用      | 需要本地GPU资源               |
| 官方SDK       | 特定厂商服务集成          | 官方维护，功能完整            | 厂商绑定                      |

### 1. 直接HTTP API调用
```python
import requests

API_URL = "https://api.openai.com/v1/chat/completions"
API_KEY = "your_api_key"

headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

data = {
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "你好！"}]
}

response = requests.post(API_URL, headers=headers, json=data)
print(response.json()["choices"][0]["message"]["content"])
```

### 2. 使用LangChain
```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

llm = ChatOpenAI(api_key="your_api_key")
messages = [HumanMessage(content="解释量子力学")]
response = llm(messages)
print(response.content)
```

### 3. 使用Transformers（本地运行）
```python
from transformers import pipeline

# 加载本地模型
generator = pipeline("text-generation", model="gpt2")

# 生成文本
result = generator("人工智能的未来是", max_length=50)
print(result[0]["generated_text"])
```

### 4. 使用官方SDK（以OpenAI为例）
```python
from openai import OpenAI

client = OpenAI(api_key="your_api_key")

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "写一首关于春天的诗"}]
)

print(response.choices[0].message.content)
```

### 关键差异说明：
1. **HTTP API**：最基础的方式，适合简单集成，但需要手动处理请求/响应
2. **LangChain**：适合构建复杂AI工作流，支持多模型切换和记忆管理
3. **Transformers**：需本地GPU资源，适合模型研究/定制化需求
4. **官方SDK**：厂商提供的最佳实践，包含高级功能但依赖特定平台

需要我针对某个使用场景提供更详细的示例吗？
